# -*- coding: utf-8 -*-
"""Entry_to deep_learning(keras_version).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tRel5cl3_TfuilrnUDjuwFNxkYIhbH_s
"""

from tensorflow import keras
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import Dense,Dropout
from tensorflow.keras.optimizers import Adam,RMSprop
from tensorflow.keras.models import Sequential
from tensorflow.keras import regularizers

(mnist_train_images,mnist_train_labels),(mnist_test_images,mnist_test_labels) = mnist.load_data()

train_images = mnist_train_images.reshape(60000,784)
test_images = mnist_test_images.reshape(10000,784)
train_images = train_images.astype('float32')
test_images = test_images.astype('float32')
test_images/=255
train_images/=255

test_label = keras.utils.to_categorical(mnist_test_labels,10)
train_label = keras.utils.to_categorical(mnist_train_labels,10)

import matplotlib.pyplot as plt

def display(num):
  print(train_label[num])
  label = train_label[num].argmax(axis=0)
  image = train_images[num].reshape([28,28])
  plt.title("Sample: %d Label: %d"%(num,label))
  plt.imshow(image,cmap=plt.get_cmap('gray_r'))
  plt.show()

display(1234)

model = Sequential()
model.add(Dense(784,activation='relu',input_shape=(784,)))
model.add(Dropout(0.5))
model.add(Dense(800,activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(10,activation='softmax'))

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

history = model.fit(train_images,train_label,epochs=10,verbose=2,validation_data=(test_images,test_label),batch_size=100)

score = model.evaluate(test_images,test_label,verbose = 2)
print("Loss: %.2f"%(score[0]*100))
print("Accuracy: %.2f"%(score[1]*100))

plt.style.use('dark_background')

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1,len(loss)+1)
plt.plot(epochs,loss,'y',label='Training Loss')
plt.plot(epochs,val_loss,'r',label='Validation loss')
plt.title("Training and Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

acc = history.history['acc']
val_acc = history.history['val_acc']
epochs = range(1,len(loss)+1)
plt.plot(epochs,acc,'y',label='Accuracy')
plt.plot(epochs,val_acc,'r',label='Validation accuracy')
plt.title("Accuracy and Validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

for x in range(500):
  label = test_label[x].argmax(axis=0)
  image = test_images[x,:].reshape([1,784])
  predicted = model.predict(image).argmax()
  image = test_images[x,:].reshape([28,28])
  if(predicted!=label):
    plt.title("Predicted: %d Label: %d" %(predicted,label))
    plt.imshow(image,cmap=plt.get_cmap('gray_r'))
    plt.show()

import numpy as np
image = train_images[0].reshape([1,784])
for i in range(1,100):
  image = np.concatenate((image,train_images[i].reshape([1,784])))
plt.imshow(image,cmap=plt.get_cmap('gray_r'))
plt.show()

